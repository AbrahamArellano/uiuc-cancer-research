#!/bin/bash
#SBATCH --job-name=tabnet_attention_analysis
#SBATCH --account=aa107-ic
#SBATCH --partition=IllinoisComputes-GPU
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --gres=gpu:1
#SBATCH --time=2:00:00
#SBATCH --output=tabnet_attention_analysis_%j.out
#SBATCH --error=tabnet_attention_analysis_%j.err

echo "üß† TABNET ATTENTION ANALYSIS - AUTOMATED SLURM PIPELINE"
echo "========================================================"
echo "Running complete 4-step attention analysis on GPU nodes"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Started: $(date)"
echo ""

# GPU check
if command -v nvidia-smi &> /dev/null; then
    echo "GPU Info: $(nvidia-smi --query-gpu=name --format=csv,noheader,nounits)"
else
    echo "‚ö†Ô∏è  GPU info not available"
fi
echo ""

# === CONFIGURATION ===
PROJECT_DIR="/u/aa107/uiuc-cancer-research"
ANALYSIS_DIR="${PROJECT_DIR}/src/analysis"
RESULTS_DIR="${PROJECT_DIR}/results/attention_analysis"
CONDA_ENV="tabnet-prostate"

# Analysis scripts in execution order
SCRIPT_1="${ANALYSIS_DIR}/variant_selector.py"
SCRIPT_2="${ANALYSIS_DIR}/attention_extractor.py"
SCRIPT_3="${ANALYSIS_DIR}/attention_analyzer.py"
SCRIPT_4="${ANALYSIS_DIR}/results_generator.py"

# === ENVIRONMENT SETUP ===
echo "üîß ENVIRONMENT SETUP"
echo "-------------------"

# Navigate to project directory
cd "${PROJECT_DIR}"
echo "Working directory: $(pwd)"

# Create results directory
mkdir -p "${RESULTS_DIR}"
echo "Results directory: ${RESULTS_DIR}"

# Load anaconda module (required on campus cluster)
echo "Loading anaconda module..."
if module load anaconda3 2>/dev/null; then
    echo "‚úÖ Anaconda module loaded"
else
    echo "‚ö†Ô∏è  Anaconda module not available - using system conda"
fi

# Initialize conda for shell script (critical for compute nodes)
echo "Initializing conda for bash..."
if [ -f "$(conda info --base)/etc/profile.d/conda.sh" ]; then
    source "$(conda info --base)/etc/profile.d/conda.sh"
    echo "‚úÖ Conda initialized from $(conda info --base)"
else
    eval "$(conda shell.bash hook)" 2>/dev/null || {
        echo "‚ùå Could not initialize conda"
        echo "üí° Make sure conda is installed and in PATH"
        exit 1
    }
fi

# Check if environment exists
if conda env list | grep -q "${CONDA_ENV}"; then
    echo "‚úÖ Found ${CONDA_ENV} environment"
else
    echo "‚ùå ${CONDA_ENV} environment not found"
    echo "üí° Create it first by running:"
    echo "   bash src/model/tests/run_tabnet_tests.sh"
    exit 1
fi

# Activate the conda environment
echo "Activating ${CONDA_ENV} environment..."
conda activate "${CONDA_ENV}"

# Verify activation
echo "‚úÖ Environment activated:"
echo "  Python: $(which python)"
echo "  Python version: $(python --version)"
echo "  Conda env: ${CONDA_DEFAULT_ENV}"
echo ""

# === GPU VERIFICATION ===
echo "üöÄ GPU VERIFICATION"
echo "==================="

# Check GPU availability
if command -v nvidia-smi &> /dev/null; then
    echo "GPU Information:"
    nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader
    
    # Check PyTorch CUDA
    python -c "
import torch
print(f'PyTorch CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'GPU device: {torch.cuda.get_device_name(0)}')
    print(f'GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB')
"
else
    echo "‚ö†Ô∏è  GPU not available - attention analysis may have device issues"
fi
echo ""

# === DEPENDENCY CHECK ===
echo "üì¶ CHECKING ATTENTION ANALYSIS DEPENDENCIES"
echo "------------------------------------------"

echo "Checking core packages..."
python -c "
import sys
try:
    import torch
    import pytorch_tabnet
    import sklearn
    import pandas as pd
    import numpy as np
    import matplotlib.pyplot as plt
    import seaborn as sns
    print('  ‚úÖ All core packages available')
    print(f'  üì¶ PyTorch: {torch.__version__} (CUDA: {torch.cuda.is_available()})')
    print(f'  üì¶ TabNet: Available')
    print(f'  üì¶ Sklearn: {sklearn.__version__}')
    print(f'  üì¶ Pandas: {pd.__version__}')
    print(f'  üì¶ Matplotlib: Available')
    print(f'  üì¶ Seaborn: Available')
except ImportError as e:
    print(f'  ‚ùå Missing package: {e}')
    sys.exit(1)
"

if [ $? -ne 0 ]; then
    echo "‚ùå Dependency check failed"
    echo "üí° Run: bash src/model/tests/run_tabnet_tests.sh"
    exit 1
fi

echo "‚úÖ All dependencies verified"

# === SCRIPT VALIDATION ===
echo ""
echo "üìã SCRIPT VALIDATION"
echo "-------------------"

SCRIPTS=("$SCRIPT_1" "$SCRIPT_2" "$SCRIPT_3" "$SCRIPT_4")
SCRIPT_NAMES=("variant_selector.py" "attention_extractor.py" "attention_analyzer.py" "results_generator.py")

for i in "${!SCRIPTS[@]}"; do
    script="${SCRIPTS[$i]}"
    name="${SCRIPT_NAMES[$i]}"
    
    if [ ! -f "$script" ]; then
        echo "‚ùå Script not found: $script"
        exit 1
    else
        echo "‚úÖ Found: $name"
    fi
done

echo "‚úÖ All analysis scripts validated"

# === PREREQUISITE CHECK ===
echo ""
echo "üß¨ PREREQUISITE CHECK"
echo "-------------------"

# Check if trained model exists
MODEL_PATH="/u/aa107/scratch/tabnet_model_20250706_151358.pkl"
if [ ! -f "$MODEL_PATH" ]; then
    echo "‚ùå Trained TabNet model not found: $MODEL_PATH"
    echo "üí° Train the model first using the training pipeline"
    exit 1
else
    MODEL_SIZE=$(du -h "$MODEL_PATH" | cut -f1)
    echo "‚úÖ TabNet model found: $MODEL_SIZE"
fi

# Check dataset
DATASET_PATH="${PROJECT_DIR}/data/processed/tabnet_csv/prostate_variants_tabnet_clean.csv"
if [ ! -f "$DATASET_PATH" ]; then
    echo "‚ùå Clean dataset not found: $DATASET_PATH"
    echo "üí° Run data processing pipeline first"
    exit 1
else
    DATASET_SIZE=$(du -h "$DATASET_PATH" | cut -f1)
    DATASET_LINES=$(wc -l < "$DATASET_PATH")
    echo "‚úÖ Dataset found: $DATASET_SIZE ($DATASET_LINES variants)"
fi

echo "‚úÖ All prerequisites satisfied"

# === ATTENTION ANALYSIS PIPELINE ===
echo ""
echo "üöÄ STARTING ATTENTION ANALYSIS PIPELINE"
echo "======================================="

# Step 1: Variant Selection
echo ""
echo "üìã STEP 1: VARIANT SELECTION"
echo "----------------------------"
echo "Purpose: Select representative pathogenic and benign variants"
echo "Script: variant_selector.py"
echo ""

START_TIME=$(date +%s)

python "$SCRIPT_1"
STEP1_EXIT_CODE=$?

if [ $STEP1_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Step 1 completed successfully"
    
    # Check output
    SELECTED_FILE="${RESULTS_DIR}/selected_variants.csv"
    if [ -f "$SELECTED_FILE" ]; then
        VARIANT_COUNT=$(tail -n +2 "$SELECTED_FILE" | wc -l)
        echo "üìä Selected $VARIANT_COUNT variants for analysis"
    fi
else
    echo "‚ùå Step 1 failed (exit code: $STEP1_EXIT_CODE)"
    exit 1
fi

# Step 2: Attention Extraction
echo ""
echo "üß† STEP 2: ATTENTION EXTRACTION"
echo "------------------------------"
echo "Purpose: Extract TabNet attention weights for selected variants"
echo "Script: attention_extractor.py"
echo ""

python "$SCRIPT_2"
STEP2_EXIT_CODE=$?

if [ $STEP2_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Step 2 completed successfully"
    
    # Check output
    ATTENTION_DIR="${RESULTS_DIR}/attention_weights"
    if [ -d "$ATTENTION_DIR" ]; then
        ATTENTION_FILES=$(find "$ATTENTION_DIR" -name "*_attention.csv" | wc -l)
        echo "üìä Generated $ATTENTION_FILES attention files"
    fi
else
    echo "‚ùå Step 2 failed (exit code: $STEP2_EXIT_CODE)"
    exit 1
fi

# Step 3: Pattern Analysis
echo ""
echo "üìä STEP 3: PATTERN ANALYSIS"
echo "--------------------------"
echo "Purpose: Analyze attention patterns without medical interpretation"
echo "Script: attention_analyzer.py"
echo ""

python "$SCRIPT_3"
STEP3_EXIT_CODE=$?

if [ $STEP3_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Step 3 completed successfully"
    
    # Check output
    PATTERNS_DIR="${RESULTS_DIR}/pattern_analysis"
    if [ -d "$PATTERNS_DIR" ]; then
        PATTERN_FILES=$(find "$PATTERNS_DIR" -name "*.txt" -o -name "*.png" | wc -l)
        echo "üìä Generated $PATTERN_FILES analysis files"
    fi
else
    echo "‚ùå Step 3 failed (exit code: $STEP3_EXIT_CODE)"
    exit 1
fi

# Step 4: Results Generation
echo ""
echo "üìã STEP 4: RESULTS GENERATION"
echo "----------------------------"
echo "Purpose: Generate final publication-ready results"
echo "Script: results_generator.py"
echo ""

python "$SCRIPT_4"
STEP4_EXIT_CODE=$?

if [ $STEP4_EXIT_CODE -eq 0 ]; then
    echo "‚úÖ Step 4 completed successfully"
    
    # Check output
    FINAL_DIR="${RESULTS_DIR}/final_results"
    if [ -d "$FINAL_DIR" ]; then
        FINAL_FILES=$(find "$FINAL_DIR" -type f | wc -l)
        echo "üìä Generated $FINAL_FILES final result files"
    fi
else
    echo "‚ùå Step 4 failed (exit code: $STEP4_EXIT_CODE)"
    exit 1
fi

# === COMPLETION SUMMARY ===
echo ""
echo "üéâ ATTENTION ANALYSIS PIPELINE COMPLETED!"
echo "========================================="
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))
echo "Completed: $(date)"
echo "Duration: ${DURATION} seconds"
echo "Job ID: $SLURM_JOB_ID"
echo ""

echo "üìÅ Output Directory Structure:"
echo "   $RESULTS_DIR/"
echo "   ‚îú‚îÄ‚îÄ selected_variants.csv                    # Selected variants"
echo "   ‚îú‚îÄ‚îÄ attention_weights/                       # Individual attention files"
echo "   ‚îÇ   ‚îú‚îÄ‚îÄ variant_*_attention.csv"
echo "   ‚îÇ   ‚îú‚îÄ‚îÄ attention_summary.csv"
echo "   ‚îÇ   ‚îî‚îÄ‚îÄ extraction_metadata.json"
echo "   ‚îú‚îÄ‚îÄ pattern_analysis/                        # Pattern analysis"
echo "   ‚îÇ   ‚îú‚îÄ‚îÄ pathogenic_vs_benign_patterns.txt"
echo "   ‚îÇ   ‚îú‚îÄ‚îÄ feature_group_analysis.txt"
echo "   ‚îÇ   ‚îú‚îÄ‚îÄ decision_step_patterns.txt"
echo "   ‚îÇ   ‚îî‚îÄ‚îÄ *.png visualizations"
echo "   ‚îî‚îÄ‚îÄ final_results/                           # Publication materials"
echo "       ‚îú‚îÄ‚îÄ tabnet_attention_analysis_report.md"
echo "       ‚îú‚îÄ‚îÄ validation_dashboard.png"
echo "       ‚îî‚îÄ‚îÄ analysis_summary.json"
echo ""

# Final verification
TOTAL_FILES=$(find "$RESULTS_DIR" -type f | wc -l)
TOTAL_SIZE=$(du -sh "$RESULTS_DIR" | cut -f1)

echo "üìä Analysis Summary:"
echo "   Total files generated: $TOTAL_FILES"
echo "   Total output size: $TOTAL_SIZE"
echo "   Analysis duration: ${DURATION} seconds"
echo "   GPU utilization: Available"
echo ""

echo "üéØ Next Steps:"
echo "   1. Review attention patterns in: $RESULTS_DIR/pattern_analysis/"
echo "   2. Examine final results in: $RESULTS_DIR/final_results/"
echo "   3. Share results with clinical experts for validation"
echo "   4. Prepare manuscript using generated materials"
echo ""

echo "‚úÖ TabNet attention analysis pipeline completed successfully!"
echo "üéâ Ready for clinical expert review and publication!"
echo ""
echo "üìã SLURM Job Summary:"
echo "   Job ID: $SLURM_JOB_ID"
echo "   Node: $SLURMD_NODENAME"
echo "   Exit Status: SUCCESS"
echo "   Log files: tabnet_attention_analysis_${SLURM_JOB_ID}.out/.err"